version: '3'

services:
  languru-agent:
    image: languru:${LANGURU_VERSION:-dev}
    build:
      context: .
      dockerfile: docker/dockerfile.dev
    container_name: languru-agent
    environment:
      - IS_PRODUCTION=${IS_PRODUCTION:-false}
      - IS_DEVELOPMENT=${IS_DEVELOPMENT:-true}
      - IS_TESTING=${IS_TESTING:-false}
      - PORT=${PORT:-80}
      - COLUMN_NAME=${COLUMN_NAME:-89}
    ports:
      - "8680:80"
    volumes:
      - ./languru:/app/languru
    command:
      - "agent"
      - "run"
    networks:
      - languru-network

  languru-llm-openai:
    image: languru:${LANGURU_VERSION:-dev}
    build:
      context: .
      dockerfile: docker/dockerfile.dev
    container_name: languru-llm-openai
    environment:
      - IS_PRODUCTION=${IS_PRODUCTION:-false}
      - IS_DEVELOPMENT=${IS_DEVELOPMENT:-true}
      - IS_TESTING=${IS_TESTING:-false}
      - PORT=${PORT:-80}
      - AGENT_BASE_URL=${AGENT_BASE_URL:-http://languru-agent}
      - LLM_BASE_URL=http://languru-llm-openai/v1
      - OPENAI_API_KEY=${OPENAI_API_KEY:-sk-xxxxxxxxxxxxxxxxxxxxxxxx}
      - COLUMN_NAME=${COLUMN_NAME:-89}
    ports:
      - "8682:80"
    volumes:
      - ./languru:/app/languru
    command:
      - "llm"
      - "run"
    networks:
      - languru-network
    depends_on:
      - languru-agent
    profiles:
      - all
      - oai
      - openai

  languru-llm-google:
    image: languru-google:${LANGURU_VERSION:-dev}
    build:
      context: .
      dockerfile: docker/dockerfile.google.dev
    container_name: languru-llm-google
    environment:
      - IS_PRODUCTION=${IS_PRODUCTION:-false}
      - IS_DEVELOPMENT=${IS_DEVELOPMENT:-true}
      - IS_TESTING=${IS_TESTING:-false}
      - PORT=${PORT:-80}
      - ACTION=languru.action.google:GoogleGenaiAction
      - AGENT_BASE_URL=${AGENT_BASE_URL:-http://languru-agent}
      - LLM_BASE_URL=http://languru-llm-google/v1
      - GOOGLE_API_KEY=${GOOGLE_API_KEY:-xxxxxxxxxxxxxxxxxxxxxxxx}
      - COLUMN_NAME=${COLUMN_NAME:-89}
    ports:
      - "8683:80"
    volumes:
      - ./languru:/app/languru
    command:
      - "llm"
      - "run"
    networks:
      - languru-network
    depends_on:
      - languru-agent
    profiles:
      - all
      - gemini
      - gg
      - google

  languru-llm-pplx:
    image: languru:${LANGURU_VERSION:-dev}
    build:
      context: .
      dockerfile: docker/dockerfile.dev
    container_name: languru-llm-pplx
    environment:
      - IS_PRODUCTION=${IS_PRODUCTION:-false}
      - IS_DEVELOPMENT=${IS_DEVELOPMENT:-true}
      - IS_TESTING=${IS_TESTING:-false}
      - PORT=${PORT:-80}
      - ACTION=languru.action.pplx:PerplexityAction
      - AGENT_BASE_URL=${AGENT_BASE_URL:-http://languru-agent}
      - LLM_BASE_URL=http://languru-llm-pplx/v1
      - PPLX_API_KEY=${PPLX_API_KEY:-pplx-xxxxxxxxxxxxxxxxxxxxxxxx}
      - COLUMN_NAME=${COLUMN_NAME:-89}
    ports:
      - "8684:80"
    volumes:
      - ./languru:/app/languru
    command:
      - "llm"
      - "run"
    networks:
      - languru-network
    depends_on:
      - languru-agent
    profiles:
      - all
      - pplx

  languru-llm-groq:
    image: languru:${LANGURU_VERSION:-dev}
    build:
      context: .
      dockerfile: docker/dockerfile.dev
    container_name: languru-llm-groq
    environment:
      - IS_PRODUCTION=${IS_PRODUCTION:-false}
      - IS_DEVELOPMENT=${IS_DEVELOPMENT:-true}
      - IS_TESTING=${IS_TESTING:-false}
      - PORT=${PORT:-80}
      - ACTION=languru.action.groq:GroqOpenaiAction
      - AGENT_BASE_URL=${AGENT_BASE_URL:-http://languru-agent}
      - LLM_BASE_URL=http://languru-llm-groq/v1
      - GROQ_API_KEY=${GROQ_API_KEY:-gsk_xxxxxxxxxxxxxxxxxxxxxxxx}
      - COLUMN_NAME=${COLUMN_NAME:-89}
    ports:
      - "8685:80"
    volumes:
      - ./languru:/app/languru
    command:
      - "llm"
      - "run"
    networks:
      - languru-network
    depends_on:
      - languru-agent
    profiles:
      - all
      - groq

  languru-llm-transformers:
    image: languru:${LANGURU_VERSION:-dev}
    build:
      context: .
      dockerfile: docker/dockerfile.cuda.dev
    container_name: languru-llm-transformers
    environment:
      - IS_PRODUCTION=${IS_PRODUCTION:-false}
      - IS_DEVELOPMENT=${IS_DEVELOPMENT:-true}
      - IS_TESTING=${IS_TESTING:-false}
      - PORT=${PORT:-80}
      - ACTION=languru.action.hf:TransformersAction
      - AGENT_BASE_URL=${AGENT_BASE_URL:-http://languru-agent}
      - LLM_BASE_URL=http://languru-llm-transformers/v1
      - MODEL_NAME=${MODEL_NAME:-mistralai/Mistral-7B-Instruct-v0.2}
      - COLUMN_NAME=${COLUMN_NAME:-89}
    ports:
      - "8686:80"
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
      - ./languru:/app/languru
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: 1
            capabilities: [gpu]
    command:
      - "llm"
      - "run"
    networks:
      - languru-network
    depends_on:
      - languru-agent
    profiles:
      - transformers

networks:
  languru-network:
    driver: bridge
